
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>CVPR 2024 Papers</title>
        
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 30px;
            background-color: white;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        th {
            background-color: #4CAF50;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: bold;
        }
        td {
            padding: 10px;
            border-bottom: 1px solid #ddd;
            vertical-align: top;
        }
        tr:hover {
            background-color: #f1f1f1;
        }
        .abstract {
            max-height: 150px;
            overflow-y: auto;
            color: #555;
        }
        .explanation {
            color: #0066cc;
            font-style: italic;
        }
        .paper-title {
            font-weight: bold;
            color: #333;
        }
        .authors {
            color: #666;
        }
    </style>
    
    </head>
    <body>
        <h1>CVPR 2024 Papers</h1>
        <table>
            <thead>
                <tr>
                    <th>Title</th>
                    <th>Authors</th>
                    <th>Quick Take</th>
                    <th>Abstract</th>
                </tr>
            </thead>
            <tbody>
    
                <tr>
                    <td class="paper-title">Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising</td>
                    <td class="authors">Haijin Zeng, Jiezhang Cao, Kai Zhang, Yongyong Chen, Hiep Luong, Wilfried Philips</td>
                    <td class="explanation">üöÄ Innovation in action: The team explores unmixing diffusion for self-supervised hyperspectral image denoising through Hyperspectral images (HSIs) have extensive applications in various fields such as medicine agriculture and industry.  Nevertheless acquiring high signal-to-noise ratio HSI poses a challenge due to narrow-band spectral filtering.</td>
                    <td class="abstract">Hyperspectral images (HSIs) have extensive applications in various fields such as medicine agriculture and industry. Nevertheless acquiring high signal-to-noise ratio HSI poses a challenge due to narrow-band spectral filtering. Consequently the importance of HSI denoising is substantial especially for snapshot hyperspectral imaging technology. While most previous HSI denoising methods are supervised creating supervised training datasets for the diverse scenes hyperspectral cameras and scan param...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">Seeing the World through Your Eyes</td>
                    <td class="authors">Hadi Alzayer, Kevin Zhang, Brandon Feng, Christopher A. Metzler, Jia-Bin Huang</td>
                    <td class="explanation">üéØ Research spotlight: A novel solution for seeing the world through your eyes that The reflective nature of the human eye is an under-appreciated source of information about what the world around us looks like.  By imaging the eyes of a moving person we capture multiple views of a scene outside the camera's direct line of sight through the reflections in the eyes.</td>
                    <td class="abstract">The reflective nature of the human eye is an under-appreciated source of information about what the world around us looks like. By imaging the eyes of a moving person we capture multiple views of a scene outside the camera's direct line of sight through the reflections in the eyes. In this paper we reconstruct a radiance field beyond the camera's line of sight using portrait images containing eye reflections. This task is challenging due to 1) the difficulty of accurately estimating eye poses an...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery</td>
                    <td class="authors">Yixuan Zhu, Ao Li, Yansong Tang, Wenliang Zhao, Jie Zhou, Jiwen Lu</td>
                    <td class="explanation">üí° Breakthrough approach: This work revolutionizes dpmesh: exploiting diffusion prior for occluded human mesh recovery with The recovery of occluded human meshes poses challenges for current methods due to the difficulty in extracting effective image features under severe occlusion.  In this paper we introduce DPMesh an innovative framework for occluded human mesh recovery that capitalizes on the profound knowledge about object structure and spatial relationships embedded in a pre-trained text-to-image diffusion model.</td>
                    <td class="abstract">The recovery of occluded human meshes poses challenges for current methods due to the difficulty in extracting effective image features under severe occlusion. In this paper we introduce DPMesh an innovative framework for occluded human mesh recovery that capitalizes on the profound knowledge about object structure and spatial relationships embedded in a pre-trained text-to-image diffusion model. Unlike previous methods reliant on conventional backbones for vanilla feature extraction DPMesh seam...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">Ungeneralizable Examples</td>
                    <td class="authors">Jingwen Ye, Xinchao Wang</td>
                    <td class="explanation">üîç Exciting research alert! This paper tackles ungeneralizable examples by The training of contemporary deep learning models heavily relies on publicly available data posing a risk of unauthorized access to online data and raising concerns about data privacy.  Current approaches to creating unlearnable data involve incorporating small specially designed noises but these methods strictly limit data usability overlooking its potential usage in authorized scenarios.</td>
                    <td class="abstract">The training of contemporary deep learning models heavily relies on publicly available data posing a risk of unauthorized access to online data and raising concerns about data privacy. Current approaches to creating unlearnable data involve incorporating small specially designed noises but these methods strictly limit data usability overlooking its potential usage in authorized scenarios. In this paper we extend the concept of unlearnable data to conditional data learnability and introduce UnGen...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">LaneCPP: Continuous 3D Lane Detection using Physical Priors</td>
                    <td class="authors">Maximilian Pittner, Joel Janai, Alexandru P. Condurache</td>
                    <td class="explanation">‚≠ê Key advancement: This study enhances lanecpp: continuous 3d lane detection using physical priors by Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving which comprises the tasks of finding the road surface and locating lane markings.  One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures while still avoiding unpredictable behavior.</td>
                    <td class="abstract">Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving which comprises the tasks of finding the road surface and locating lane markings. One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures while still avoiding unpredictable behavior. While previous methods rely on fully data-driven approaches we instead introduce a novel approach LaneCPP that uses a continuous 3D lane detection model leveragi...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">CityDreamer: Compositional Generative Model of Unbounded 3D Cities</td>
                    <td class="authors">Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu</td>
                    <td class="explanation">üéØ Research spotlight: A novel solution for citydreamer: compositional generative model of unbounded 3d cities that 3D city generation is a desirable yet challenging task since humans are more sensitive to structural distortions in urban environments.  Additionally generating 3D cities is more complex than 3D natural scenes since buildings as objects of the same class exhibit a wider range of appearances compared to the relatively consistent appearance of objects like trees in natural scenes.</td>
                    <td class="abstract">3D city generation is a desirable yet challenging task since humans are more sensitive to structural distortions in urban environments. Additionally generating 3D cities is more complex than 3D natural scenes since buildings as objects of the same class exhibit a wider range of appearances compared to the relatively consistent appearance of objects like trees in natural scenes. To address these challenges we propose CityDreamer a compositional generative model designed specifically for unbounded...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">HEAL-SWIN: A Vision Transformer On The Sphere</td>
                    <td class="authors">Oscar Carlsson, Jan E. Gerken, Hampus Linander, Heiner Spie√ü, Fredrik Ohlsson, Christoffer Petersson, Daniel Persson</td>
                    <td class="explanation">üéØ Research spotlight: A novel solution for heal-swin: a vision transformer on the sphere that High-resolution wide-angle fisheye images are becoming more and more important for robotics applications such as autonomous driving.  However using ordinary convolutional neural networks or vision transformers on this data is problematic due to projection and distortion losses introduced when projecting to a rectangular grid on the plane.</td>
                    <td class="abstract">High-resolution wide-angle fisheye images are becoming more and more important for robotics applications such as autonomous driving. However using ordinary convolutional neural networks or vision transformers on this data is problematic due to projection and distortion losses introduced when projecting to a rectangular grid on the plane. We introduce the HEAL-SWIN transformer which combines the highly uniform Hierarchical Equal Area iso-Latitude Pixelation (HEALPix) grid used in astrophysics and...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">3D Paintbrush: Local Stylization of 3D Shapes with Cascaded Score Distillation</td>
                    <td class="authors">Dale Decatur, Itai Lang, Kfir Aberman, Rana Hanocka</td>
                    <td class="explanation">üîç Exciting research alert! This paper tackles 3d paintbrush: local stylization of 3d shapes with cascaded score distillation by We present 3D Paintbrush a technique for automatically texturing local semantic regions on meshes via text descriptions.  Our method is designed to operate directly on meshes producing texture maps which seamlessly integrate into standard graphics pipelines.</td>
                    <td class="abstract">We present 3D Paintbrush a technique for automatically texturing local semantic regions on meshes via text descriptions. Our method is designed to operate directly on meshes producing texture maps which seamlessly integrate into standard graphics pipelines. We opt to simultaneously produce a localization map (to specify the edit region) and a texture map which conforms to it. This approach improves the quality of both the localization and the stylization. To enhance the details and resolution of...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">Test-Time Linear Out-of-Distribution Detection</td>
                    <td class="authors">Ke Fan, Tong Liu, Xingyu Qiu, Yikai Wang, Lian Huai, Zeyu Shangguan, Shuang Gou, Fengjian Liu, Yuqian Fu, Yanwei Fu, Xingqun Jiang</td>
                    <td class="explanation">üéØ Research spotlight: A novel solution for test-time linear out-of-distribution detection that Out-of-Distribution (OOD) detection aims to address the excessive confidence prediction by neural networks by triggering an alert when the input sample deviates significantly from the training distribution (in-distribution) indicating that the output may not be reliable.  Current OOD detection approaches explore all kinds of cues to identify OOD data such as finding irregular patterns in the feature space logit space gradient space or the raw image space.</td>
                    <td class="abstract">Out-of-Distribution (OOD) detection aims to address the excessive confidence prediction by neural networks by triggering an alert when the input sample deviates significantly from the training distribution (in-distribution) indicating that the output may not be reliable. Current OOD detection approaches explore all kinds of cues to identify OOD data such as finding irregular patterns in the feature space logit space gradient space or the raw image space. Surprisingly we observe a linear trend be...</td>
                </tr>
        
                <tr>
                    <td class="paper-title">Guided Slot Attention for Unsupervised Video Object Segmentation</td>
                    <td class="authors">Minhyeok Lee, Suhwan Cho, Dogyoon Lee, Chaewon Park, Jungho Lee, Sangyoun Lee</td>
                    <td class="explanation">üí° Breakthrough approach: This work revolutionizes guided slot attention for unsupervised video object segmentation with Unsupervised video object segmentation aims to segment the most prominent object in a video sequence.  However the existence of complex backgrounds and multiple foreground objects make this task challenging.</td>
                    <td class="abstract">Unsupervised video object segmentation aims to segment the most prominent object in a video sequence. However the existence of complex backgrounds and multiple foreground objects make this task challenging. To address this issue we propose a guided slot attention network to reinforce spatial structural information and obtain better foreground-background separation. The foreground and background slots which are initialized with query guidance are iteratively refined based on interactions with tem...</td>
                </tr>
        
            </tbody>
        </table>
    </body>
    </html>
    